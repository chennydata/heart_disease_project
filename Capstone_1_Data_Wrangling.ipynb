{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What kind of cleaning steps did you perform?\n",
    "The data I decided to use is the heart disease data set from University of California Irvine machine learning repository. The data was very messy and needed to be cleaned. Initially, this data was downloadable only as text file and every feature in a row was separated by a single space; this created a big problem because if I would have just loaded the text file directly onto Python through ‘pd.read’ it would make every feature stick together. To handle this problem, I used ‘separator’ argument from pandas library and set that separator to a single space so that Python could recognize that features separated by a space should be placed into different columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    0    63  1.1  1.2  1.3  1.4   -9    4    140     ...       2.4  \\\n",
      "NaN  2.0  0.0  44.0  1.0  1.0  1.0  1.0 -9.0  4.0  130.0     ...       1.0   \n",
      "NaN  3.0  0.0  60.0  1.0  1.0  1.0  1.0 -9.0  4.0  132.0     ...       2.0   \n",
      "NaN  4.0  0.0  55.0  1.0  1.0  1.0  1.0 -9.0  4.0  142.0     ...       1.0   \n",
      "NaN  5.0  0.0  66.0  1.0  1.0  0.0  0.0 -9.0  3.0  110.0     ...       1.0   \n",
      "NaN  6.0  0.0  66.0  1.0  1.0  0.0  1.0 -9.0  3.0  120.0     ...       1.0   \n",
      "\n",
      "     1.16  1.17  1.18  1.19  1.20  1.21  0.7.1  5.5  Unnamed: 75  \n",
      "NaN   1.0   1.0   1.0   1.0   1.0   1.0   0.50 -9.0          NaN  \n",
      "NaN   1.0   1.0   1.0   1.0   7.0   2.0   0.52  4.1          NaN  \n",
      "NaN   1.0   1.0   1.0   1.0   1.0   1.0   0.73  6.5          NaN  \n",
      "NaN   1.0   1.0   1.0   1.0   1.0   1.0   0.73  8.0          NaN  \n",
      "NaN   1.0   1.0   1.0   1.0   1.0   1.0   0.76  4.2          NaN  \n",
      "\n",
      "[5 rows x 76 columns]\n",
      "Index(['1', '0', '63', '1.1', '1.2', '1.3', '1.4', '-9', '4', '140', '0.1',\n",
      "       '260', '0.2', '0.3', '0.4', '0.5', '-9.1', '0.6', '1.5', '1.6', '22',\n",
      "       '85', '0.7', '0.8', '1.7', '0.9', '0.10', '5', '4.5', '-9.2', '5.1',\n",
      "       '112', '62', '160', '90', '140.1', '80', '1.8', '0.11', '3', '2', '20',\n",
      "       '19', '-9.3', '-9.4', '0.12', '-9.5', '-9.6', '-9.7', '-9.8', '-9.9',\n",
      "       '-9.10', '-9.11', '-9.12', '2.1', '27', '85.1', '2.2', '1.9', '1.10',\n",
      "       '2.3', '1.11', '1.12', '1.13', '1.14', '1.15', '2.4', '1.16', '1.17',\n",
      "       '1.18', '1.19', '1.20', '1.21', '0.7.1', '5.5', 'Unnamed: 75'],\n",
      "      dtype='object')\n",
      "     1    0    63  1.1  1.2  1.3  1.4   -9    4    140     ...       2.4  \\\n",
      "0  2.0  0.0  44.0  1.0  1.0  1.0  1.0 -9.0  4.0  130.0     ...       1.0   \n",
      "1  3.0  0.0  60.0  1.0  1.0  1.0  1.0 -9.0  4.0  132.0     ...       2.0   \n",
      "2  4.0  0.0  55.0  1.0  1.0  1.0  1.0 -9.0  4.0  142.0     ...       1.0   \n",
      "3  5.0  0.0  66.0  1.0  1.0  0.0  0.0 -9.0  3.0  110.0     ...       1.0   \n",
      "4  6.0  0.0  66.0  1.0  1.0  0.0  1.0 -9.0  3.0  120.0     ...       1.0   \n",
      "\n",
      "   1.16  1.17  1.18  1.19  1.20  1.21  0.7.1  5.5  Unnamed: 75  \n",
      "0   1.0   1.0   1.0   1.0   1.0   1.0   0.50 -9.0          NaN  \n",
      "1   1.0   1.0   1.0   1.0   7.0   2.0   0.52  4.1          NaN  \n",
      "2   1.0   1.0   1.0   1.0   1.0   1.0   0.73  6.5          NaN  \n",
      "3   1.0   1.0   1.0   1.0   1.0   1.0   0.73  8.0          NaN  \n",
      "4   1.0   1.0   1.0   1.0   1.0   1.0   0.76  4.2          NaN  \n",
      "\n",
      "[5 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "heart = pd.read_csv('Desktop/long-beach-va.data_clean',encoding='latin-1',sep =' ')\n",
    "print(heart.head())\n",
    "print(heart.columns) #as we can see, the column names are not clear\n",
    "heart = heart.reset_index() #remove the index from the data\n",
    "del heart['index']\n",
    "print(heart.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns_list = [2,3,8,9,11,15,18,31,37,39,40,43,50,57]\n",
    "new_heart = heart[heart.columns[keep_columns_list]]\n",
    "column_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','target']\n",
    "new_heart.columns = column_names\n",
    "heart_data = new_heart # give the new data set an appropriate name for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
      "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     1       1  \n",
      "1   0     2       1  \n",
      "2   0     2       1  \n",
      "3   0     2       1  \n",
      "4   0     2       1  \n"
     ]
    }
   ],
   "source": [
    "print(heart_data.head())   # now that the data has been cleaned up and contains only needed columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. How did you deal with missing values?\n",
    "This data set does not contain missing and null value. However, every feature in each row is recorded as a numerical value even if it should be a categorical input. To handle this, I used ‘.replace()’ method to replace the values that should be categorical so that the data set looks better at a glance. Sometimes, it’d be useful to revert some input back to numerical values such as bernoulli distribution, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null int64\n",
      "sex         303 non-null int64\n",
      "cp          303 non-null int64\n",
      "trestbps    303 non-null int64\n",
      "chol        303 non-null int64\n",
      "fbs         303 non-null int64\n",
      "restecg     303 non-null int64\n",
      "thalach     303 non-null int64\n",
      "exang       303 non-null int64\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int64\n",
      "ca          303 non-null int64\n",
      "thal        303 non-null int64\n",
      "target      303 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.2 KB\n"
     ]
    }
   ],
   "source": [
    "heart_data.info() # as we can see that there is no missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex                cp  trestbps  chol         fbs restecg  thalach  \\\n",
      "0   63    male           no pain       145   233  fast blood   False      150   \n",
      "1   37    male  non-anginal pain       130   250      normal    True      187   \n",
      "2   41  female   atypical angina       130   204      normal   False      172   \n",
      "3   56    male   atypical angina       120   236      normal    True      178   \n",
      "4   57  female    typical angina       120   354      normal    True      163   \n",
      "\n",
      "   exang  oldpeak        slope  ca          thal   target  \n",
      "0  False      2.3    upsloping   0        normal  at risk  \n",
      "1  False      3.5    upsloping   0  fixed detect  at risk  \n",
      "2  False      1.4  downsloping   0  fixed detect  at risk  \n",
      "3  False      0.8  downsloping   0  fixed detect  at risk  \n",
      "4   True      0.6  downsloping   0  fixed detect  at risk  \n"
     ]
    }
   ],
   "source": [
    "heart_data['sex']=heart_data['sex'].replace([0,1],['female','male'])\n",
    "heart_data['cp']=heart_data['cp'].replace([0,1,2,3],['typical angina', 'atypical angina', 'non-anginal pain', 'no pain'])\n",
    "heart_data['target']=heart_data['target'].replace([0,1],['not at risk', 'at risk'])\n",
    "heart_data['fbs']=heart_data['fbs'].replace([0,1],['normal','fast blood'])\n",
    "heart_data['slope']=heart_data['slope'].replace([0,1,2], ['upsloping', 'flat', 'downsloping'])\n",
    "heart_data['restecg']=heart_data['restecg'].replace([0,1],['False','True'])\n",
    "heart_data['exang']=heart_data['exang'].replace([0,1],['False','True'])\n",
    "heart_data['thal']=heart_data['thal'].replace([1,2,3], ['normal', 'fixed detect','reversable detect'])\n",
    "print(heart_data.head()) # now the data is looking nice and pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Were there outliers, and how did you handle them?\n",
    "Below, I wrote up the outliers function to find the outliers of the numerical records in our data. There are some outliers but does not range too far part from each other. For now, I will keep these outliers and will apply central limit theorem and bootstrapping on it to eliminate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(column):\n",
    "    ls = sorted(list(column))\n",
    "    Q1 = ls[round(len(ls)*0.25)]\n",
    "    Q3 = ls[round(len(ls)*0.75)]\n",
    "    IQR = Q3 - Q1\n",
    "    low_out = Q1 - 1.5 * IQR\n",
    "    high_out = Q3 + 1.5 * IQR\n",
    "    outlier_list = []\n",
    "    for i in range(len(ls)):\n",
    "        if (ls[i] < low_out) or (ls[i] > high_out):\n",
    "            print(ls[i])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "407\n",
      "409\n",
      "417\n",
      "564\n"
     ]
    }
   ],
   "source": [
    "outliers(heart_data['chol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "174\n",
      "178\n",
      "178\n",
      "180\n",
      "180\n",
      "180\n",
      "192\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "outliers(heart_data['trestbps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "outliers(heart_data['thalach'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2\n",
      "4.2\n",
      "4.4\n",
      "5.6\n",
      "6.2\n"
     ]
    }
   ],
   "source": [
    "outliers(heart_data['oldpeak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
